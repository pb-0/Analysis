{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-genesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('Base_Agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Import orthogonal data sets and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv('Base_Agg_time_period_1.csv')\n",
    "df_2 = pd.read_csv('Base_Agg_time_period_2.csv')\n",
    "df_3 = pd.read_csv('Base_Agg_time_period_3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_1,df_2,df_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join data to additional features\n",
    "# df_all = df_1.merge(df_2_fts, on='company_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: flatten df for nested field\n",
    "df_all_flat = df_all.set_index(['company_id','events_field'])['val'].unstack(fill_value=0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: drop duplicates and merge to flattened field\n",
    "df_all = df_all.drop_duplicates()\n",
    "df_all = df_all.drop(['events_field'], axis=1)\n",
    "df_final_flat = df_all.merge(df_all_flat, on='company_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accessible-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optional: combining features\n",
    "combine_fts = ['channel','sku','type']\n",
    "df_all['ft_set'] = df_all[combine_fts].apply(lambda x: '_'.join(x.values.astype(str)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-sunset",
   "metadata": {},
   "source": [
    "## Test, Train, Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1: drop train index from test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Up sample dataframe\n",
    "df_sample= df_final_flat\n",
    "df_cids=pd.DataFrame()\n",
    "\n",
    "#Sample 80% of cids for Trraining set\n",
    "df_cids['company_id']=df_sample['company_id'].unique().flatten()\n",
    "df_train_cids=df_cids.sample(frac=0.8, random_state=1)\n",
    "\n",
    "\n",
    "df_train = df_sample.reset_index().merge(df_train_cids, on='company_id', how='inner').set_index('index')\n",
    "\n",
    "df_test_validate = df_sample.drop(df_train.index)\n",
    "\n",
    "df_test_cids = df_test_validate['company_id'].sample(frac=1, random_state=1)\n",
    "\n",
    "df_test=df_test_validate.reset_index().merge(df_test_cids, on='company_id', how='inner').set_index('index')\n",
    "\n",
    "df_validate = df_test_validate.drop(df_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "Oversample undersample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cids_pos = df_sample[df_sample['fc30']==1]['company_id']\n",
    "df_cids_neg = df_sample[df_sample['fc30']==0]['company_id']\n",
    "df_cids_neg_sample = df_cids_neg.sample(frac=1/oversample, random_state=1)\n",
    "df_cids_sample = pd.concat([df_cids_pos, df_cids_neg_sample])\n",
    "df_train = df_train.merge(df_cids_sample, on='company_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check unique id counts in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Train cids:{df_train.company_id.nunique()}, Test cids:{df_test.company_id.nunique()}, \n",
    "       Validate cids:{df_validate.company_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-order",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check total records in test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Train records:{len(df_train)}, Test records:{len(df_test)}, Validate records:{len(df_validate)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for exclusivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train.merge(df_test, on='company_id', how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test.merge(df_validate, on='company_id', how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_validate.merge(df_train, on='company_id', how='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"Train avg:{df_train.fc30.mean():.3f}, Test avg:{df_test.fc30.mean():.3f}, \\\n",
    "       Validate cids:{df_validate.fc30.mean():.3f}\")\n",
    "       \n",
    "print (f\"Train SD:{np.std(df_train['fc30']):.3f}, Test SD:{np.std(df_train['fc30']):.3f}, \\\n",
    "       Validate cids:{np.std(df_validate['fc30']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-letters",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varying-memorial",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-05fee1a21ecb>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-05fee1a21ecb>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    np.where(((dfb[c].isna()=True) & (dfb['avg'].isna()==True)),dfb['avg'].mean(), dfb[c]))\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def multiple_imp(df, cols, keys):\n",
    "    def __init__(self, df):\n",
    "        self.df=df\n",
    "    dfn = df.copy()\n",
    "    for c in cols:\n",
    "        dfg = df.groupby(keys).agg(avg=(c, np.mean)).reset_index()\n",
    "        dfb = df.merge(dfg, on=keys, how='inner')\n",
    "        \n",
    "        dfn[c] = np.where(((dfb[c].isna()==True)&(dfb['avg'].isna()==False)), dfb['avg'],\\\n",
    "                       np.where(((dfb[c].isna()=True) & (dfb['avg'].isna()==True)),dfb['avg'].mean(), dfb[c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e.g. impute business name length from other features\n",
    "df_train = multiple_imp(df_train,['business_name_length'], ['sku','channel','milestones_completed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bin continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "binned = ['business_name_length','ccardexpyear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in binned:\n",
    "    df_train.loc[:,b] = pd.qcut(df_train[b],q=10,labels=False, duplicates='drop')\n",
    "    df_test.loc[:,b] = pd.qcut(df_test[b],q=10,labels=False, duplicates='drop')\n",
    "    df_validate.loc[:,b] = pd.qcut(df_validate[b],q=10,labels=False, duplicates='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-storm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ohe categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = ['channel','sku','state','cotype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace null values\n",
    "for c in ohe:\n",
    "    df_train.loc[:,c] = np.where(df_train[c].isna()==True,'None',df_train[c])\n",
    "    df_test.loc[:,c] = np.where(df_test[c].isna()==True,'None',df_test[c])\n",
    "    df_validate.loc[:,c] = np.where(df_validate[c].isna()==True,'None',df_validate[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handled-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot ohe dataset\n",
    "df_train = pd.get_dummies(df_train, columns=ohe, prefix=ohe)\n",
    "df_test = pd.get_dummies(df_test, columns=ohe, prefix=ohe)\n",
    "df_validate = pd.get_dummies(df_validate, columns=ohe, prefix=ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set class weights for inbalance class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"class_weights\"] = np.where(df_train[\"fc30\"]==0, 1-df_train.fc30_mean(), df_train.fc30.mean())\n",
    "df_test[\"class_weights\"] = np.where(df_test[\"fc30\"]==0, 1-df_test.fc30_mean(), df_test.fc30.mean())\n",
    "df_validate[\"class_weights\"] = np.where(df_validate[\"fc30\"]==0, 1-df_validate.fc30_mean(), df_validate.fc30.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude identifiers, immutables, dependent var\n",
    "ex_cols = ['company_id','fc30','signupdate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_set = list(set(df_train.columns) & set(df_test.columns) & set(df_validate.columns) - set(ex_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train[df_train.isna().any(axis=1)]) -- should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-registrar",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_test[df_test.isna().any(axis=1)]) -- should be 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-nicholas",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test dfs\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[ft_set]\n",
    "y_train = df_train[['fc30']]\n",
    "\n",
    "X_test = df_test[ft_set]\n",
    "y_test = df_test[['fc30']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_train = RFC(n_estimators=50).fit(X_train,y_train.values.ravel(), sample_weight=df_train['class_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['fc_score'] = rfc_train.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-webmaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['fc_class'] = rfc_train.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-number",
   "metadata": {},
   "source": [
    "## Evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f score function\n",
    "    compute tp, fp, tn, fn totals at each cut off\n",
    "    calculate fscore, pcsn, rcll for each cut off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_score(df):\n",
    "    d=pd.DataFrame()\n",
    "    for c in range(0,1000):\n",
    "        tp = df[(df['fc_score']>=(c/1000)) & (df['fc30']==1)].company_id.nunique()\n",
    "        fp = df[(df['fc_score']>=(c/1000)) & (df['fc30']==0)].company_id.nunique()\n",
    "        tn = df[(df['fc_score']<(c/1000)) & (df['fc30']==0)].company_id.nunique()\n",
    "        fn = df[(df['fc_score']<(c/1000)) & (df['fc30']==1)].company_id.nunique()\n",
    "        \n",
    "        if tp==0:\n",
    "            pcsn=0\n",
    "            rcll=0\n",
    "            fs=0\n",
    "        else:\n",
    "            pcsn = np.where(tp+fp==0,0,tp/(tp+fp))\n",
    "            rcll = np.where(tp+fn==0,0,tp/(tp+fn))\n",
    "            fs=2*(pcsn*rcll)/(pcsn+rcll)\n",
    "            \n",
    "        d.loc[c,'fs'] = fs\n",
    "        d.loc[c,'tpr'] = rcll\n",
    "        d.loc[c,'pcsn'] = pcsn\n",
    "        d.loc[c,'fpr'] = fp/(tn+fp)\n",
    "        d.loc[c,'fpr'] = d.loc[c, 'fpr'].round(2)\n",
    "    return d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_df = f_score(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_df.fs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find optimum cut off for fscore, tpr, fpr\n",
    "fscore_df[fscore_df['fs']==fscore_df['fs'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "fscore_df[fscore_df['tpr']==fscore_df['tpr'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-press",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot(x='fpr', y='tpr', label='Model/Build/Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate AUC\n",
    "np.sum(fs['tpr']-fs['fpr'])/(len(fs)-sum(fs['fpr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate log loss\n",
    "log_loss = np.sum(-(df_test['fc30']*np.where(df_test['fc_score']==0,0,np.log(df_test['fc_score']))\n",
    "                    + (1-df_test['fc30'])*np.where(df_test['fc_score']==1,np.log(1),np.log(1-df_test['fc_score']))))\n",
    "            / len(df_test)\n",
    "log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-equivalent",
   "metadata": {},
   "source": [
    "## Model exploration (feature importances, logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greek-irish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printout feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imps = rfc_train.feature_importances_\n",
    "\n",
    "fi = pd.DataFrame()\n",
    "for f in feature_imps.argsort()[::-1]:\n",
    "    fi.loc[f, 'feature'] = X_train.columns[f]\n",
    "    fi.loc[f, 'score'] = feature_imps[f]\n",
    "#     print(f\"{X_train.columns[f]:<20}\", f\"{feature_imps[f]:.3f}\")\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "#printout premutation importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imps = permutation_importance(rfc_train, X_train, y_train).importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = pd.DataFrame()\n",
    "for f in perm_imps.argsort()[::-1]:\n",
    "    pi.loc[f, 'feature'] = X_train.columns[f]\n",
    "    pi.loc[f, 'score'] = perm_imps[f]\n",
    "\n",
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore feature relationships using log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sms\n",
    "from statsmodels.formula.api import logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logit('fc30 ~ business_name_length', df_test).fit()\n",
    "log.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-prefix",
   "metadata": {},
   "source": [
    "## Run a second model (GBT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import XGboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portable-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp, Trials, fmin, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "active-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_space = {\n",
    "    \"n_estimators\":hp.choice(\"n_estimators\",[2,4,5,6,18,20,100,150,200,250]),\n",
    "    \"learning_rate\":hp.choice(\"learning_rate\",[0.05,0.1,0.15,0.2, 0.25,0.3,0.4,0.6,0.8,2,4,6,8,12]),\n",
    "    \"max_depth\":hp.choice(\"max_depth\",[1,2,3,4,5,6,7,8,9,50,100]) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_fx(params):\n",
    "    model = XGBClassifier(**params)\n",
    "    model_run=model.fit(X_train, y_train.values.ravel(),\n",
    "        eval_set = [(X_train, y_test)],\n",
    "        eval_metric = ['auc'],\n",
    "        sample_weight = df_train['class_weights'])\n",
    "    auc_i = -max(model_run.evals_result()['validation_0']['auc'])\n",
    "    return auc_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "gbt_opt = fmin(metrics_fx,space=hp_space,max_evals=100,algo=tpe.suggest,trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gbto = GradientBoostingClassifier(**gbt_opt).fit(X_train,y_train.values.ravel(),sample_weight=df_train['class_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_gbt = df_test.copy()\n",
    "df_test_gbt['fc_score'] = model_gbto.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbto_fs = f_score(df_test_gbt)\n",
    "gbto_fs.fs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-snapshot",
   "metadata": {},
   "source": [
    "## compare methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "worse-jefferson",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rfc_fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-68fdc8a323f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrfc_fs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tpr_rfc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc_fs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tpr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mscore_combo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc_fscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rfc_fs' is not defined"
     ]
    }
   ],
   "source": [
    "rfc_fs = fscore_df\n",
    "rfc_fs['tpr_rfc'] = rfc_fs['tpr']\n",
    "gbto_fs['tpr_gbt'] =  gbto_fs['tpr']\n",
    "rfc_fs = rfc_fs.drop('tpr', axis=1)\n",
    "gbto_fs = gbto_fs.drop('tpr', axis=1)\n",
    "score_combo = rfc_fs.merge(gbto_fs[['tpr_gbt','fpr']], on='fpr', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot score combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-devil",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_combo.plot(x='fpr', y=['tpr_gbt','tpr_rfc'], label=['GBT model/build/date','RFC model/build/date'], figsize=(11,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-single",
   "metadata": {},
   "source": [
    "## Look at accuracy within certain subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "#How accurate are we for new customers?\n",
    "\n",
    "def f_score_wk(df):\n",
    "    df __init__(self,df):\n",
    "        self.df=df\n",
    "    fs = pd.DataFrame()\n",
    "    \n",
    "    for i in range(0,5):\n",
    "        d = f_score(df[df['wks_from_signup']]==i)\n",
    "        fs.loc[i,'fscore'] = d['fs'].max()\n",
    "        fs.loc[i,'pcsn'] = d[d['fs']==d['fs'].max()]['pcsn'].max()\n",
    "        fs.loc[i,'rcll'] = d[d['fs']==d['fs'].max()]['tpr'].max()\n",
    "    return fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_w = f_score_wk(df_test)\n",
    "gbt_w = f_score_wk(df_test_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-september",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = rfc_w.melt(id_vars='wk',value_vars=['rcll','pcsn','rcll'], var_name='metric', value_name='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-illness",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,11))\n",
    "sns.lineplot(x='wk',y='score',hue='metric',palette='ocean_r', linewidth=4,data=dfplot[dfplot['metric'].isin(['fscore','pcsn'])])\n",
    "plt.axline(xy1=(0,.85), xy2=(4,.85), color='r', linestyle=':',label='Baseline F score')\n",
    "plt.xlabel('Weeks from signup', fontsize=16)\n",
    "plt.ylabel('Score',fontsize=16)\n",
    "plt.legend(fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-revision",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_e(df, label_encoding):\n",
    "    D = df.copy()\n",
    "    for l in label_encoding:\n",
    "        label_values = list(D[1].unique())\n",
    "        D.loc[:,1] = D.apply(lambda row:label_values.index(row[1])), axis=1)\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "Boolean Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "bools = list(set(list(df_test.columns))-set(cats))\n",
    "for col in bools:\n",
    "    df_test[col] = df_test[col].fillna(9999)\n",
    "    df_test[col] = df_test[col].astype('datetime64[D]')\n",
    "\n",
    "df_test['date'] = df_test['date'].astype('datetime64[D]')\n",
    "\n",
    "def bool_mask(x):\n",
    "    return np.where(x<=df_test['date'],1,0)\n",
    "\n",
    "for col in bools:\n",
    "    df_test[col] = df_test[col].map(bool_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-pregnancy",
   "metadata": {},
   "source": [
    "## Pivoting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = df_gb.pivot(index='company_id', columns='step',values='ts').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-jordan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot_ts['one_to_two'] = pd.to_timedelta(pd.to_datetime(df_pivot_ts['two']) - pd.to_datetime(df_pivot_ts['one']))\n",
    "df_pivot_ts['one_to_two'] = df_pivot_ts['one_to_two'].dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-feature",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(df_pivot_ts['one_to_two'].dropna(),90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
